{
    "model": {
        "base_model": "Qwen/Qwen3-0.6B",
        "teacher_model": "Qwen/Qwen3-32B",
        "include_response": true,
        "is_do_alignment": false,
        "alignment_strategy": "first",
        "projector": {
            "type": "C2CProjector",
            "params": {
                "hidden_dim": 1024,
                "intermediate_dim": 1024,
                "num_layers": 3,
                "dropout": 0.1,
                "initial_temperature": 1.0,
                "final_temperature": 0.001,
                "anneal_steps": 116
            }
        },
        "mapping": "last_aligned"
    },
    "training": {
        "learning_rate": 0.0001,
        "weight_decay": 0.01,
        "num_epochs": 1,
        "max_length": 768,
        "device": "cuda",
        "scheduler_type": "linear",
        "warmup_ratio": 0.1,
        "max_grad_norm": 1.0,
        "gradient_accumulation_steps": 8,
        "per_device_train_batch_size": 1,
        "num_processes": 8,
        "freeze": [
            "teacher",
            "base"
        ],
        "seed": 42
    },
    "output": {
        "output_dir": "local/checkpoints/include_response_test",
        "save_steps": 5,
        "eval_steps": 200,
        "wandb_config": {
            "project": "Rosetta",
            "mode": "offline",
            "entity": "nics-efc",
            "run_name": "include_response_test"
        }
    },
    "data": {
        "type": "LLMGeneratedChatDataset",
        "kwargs": {
            "split": "train",
            "max_word_count": 768,
            "num_samples": null,
            "data_path": "../rosetta_train/local/teacher_datasets/gsm8k_qwen3_32b_output_train/dataset_finished"
        },
        "train_ratio": 0.99
    }
}